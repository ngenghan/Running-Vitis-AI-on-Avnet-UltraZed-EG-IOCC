<!DOCTYPE html>
<html>
<head>
<title>Vitis-AI-documentation.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<table width="100%">
  <tr width="100%">
    <td align="center">
        <img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/>
        <h1>Vitis AI Development Flow on Avnet Ultrazed-EG board</h1>
    </td>
 </tr>
 </table>
<h1 id="1-introduction">1. Introduction</h1>
<p>This document serves as an in-depth documentation of the Vitis-AI development flow on the Avnet UltraZed-EG. The 2020.2 version of the <a href="https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html">Xilinx Unfied Software Platform</a> application will be used, along with <a href="https://github.com/Xilinx/Vitis-AI/tree/1.3.2">v1.3.2 of the Vitis-AI stack</a>.
<br />
<br /></p>
<h2 id="11-pre-requisites">1.1. Pre-requisites</h2>
<p>The following applications and files are necessary for the Vitis-AI development flow:</p>
<h4 id="applications-and-packages">Applications and packages</h4>
<ul>
<li><a href="#docker-installation">Docker</a></li>
<li><a href="#epel-package-download">Extra Packages for Enterprise Linux (EPEL)</a></li>
<li><a href="#git-installation">Git</a></li>
<li><a href="#vitis-ai-runtime-(vart)-set-up">Vitis AI Runtime (VART)</a></li>
<li><a href="#xilinx-unified-software-platform-installation">Xilinx Unified Software Platform 2020.2</a></li>
</ul>
<h4 id="files-and-repositories">Files and repositories</h4>
<ul>
<li><a href="#avnet-ultrazed-eg-iocc-base-vitis-platform-project-download">Avnet UltraZed-EG IOCC base Vitis Platform Project</a></li>
<li><a href="#xilinx-vitis-ai-docker-image-download">Xilinx Vits-AI Docker image 1.3.598</a></li>
<li><a href="#xilinx-vitis-ai-git-repository-download">Xilinx Vitis-AI Git repository v1.3.2</a></li>
<li><a href="#xilinx-zynqmp-common-image">Xilinx ZYNQMP common image</a></li>
</ul>
<p>For the purposes of this documentation, we will be using an example from the following Xilinx Vitis-AI-Tutorials repository as well:</p>
<ul>
<li><a href="#dogs-vs-cats-data-download">Dogs vs Cats dataset</a></li>
<li><a href="#xilinx-vitis-ai-tutorials-git-repository-download">Xilinx Vitis-AI-Tutorials</a></li>
</ul>
<h3 id="docker-installation"><strong>Docker Installation</strong></h3>
<p>Install Docker for your operating system from the <a href="https://docs.docker.com/engine/install/">Docker website</a>.</p>
<h3 id="epel-package-download"><strong>Epel Package Download</strong></h3>
<p>Download the Extra Packages for Enterprise Linux on the host.</p>
<pre class="hljs"><code><div>sudo yum install -y epel-release
</div></code></pre>
<h3 id="git-installation"><strong>Git Installation</strong></h3>
<p>Much of Vitis-AI's libraries and tools are hosted on GitHub. Git can be installed using the Yum package manager.</p>
<pre class="hljs"><code><div>sudo yum install -y git
</div></code></pre>
<h3 id="vitis-ai-runtime-vart-set-up"><strong>Vitis AI Runtime (VART) Set Up</strong></h3>
<p><em>The VART set up procedure is adapted from the <a href="https://github.com/Xilinx/Vitis-AI/blob/1.3.2/setup/mpsoc/VART/README.md">official Xilinx documentation</a>.</em></p>
<ol>
<li>
<p>Download and execute the <a href="https://www.xilinx.com/bin/public/openDownload?filename=sdk-2020.2.0.0.sh">sdk-2020.2.0.0.sh</a> script for setting up the Petalinux cross compilation environment.</p>
</li>
<li>
<p>When the installation is complete, run <code>source</code> on the <code>environment-setup-aarch64-xilinx-linux</code> file. This step is necessary before cross-compiling the AI models.</p>
</li>
</ol>
<pre class="hljs"><code><div>source [INSTALLATION-DIRECTORY]/environment-setup-aarch64-xilinx-linux
</div></code></pre>
<ol start="3">
<li>Download the <a href="https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_2020.2-r1.3.2.tar.gz">vitis_ai_2020.2-r1.3.2.tar.gz</a>.</li>
</ol>
<pre class="hljs"><code><div>wget https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_2020.2-r1.3.2.tar.gz -O vitis_ai_2020.2-r1.3.2.tar.gz
</div></code></pre>
<ol start="4">
<li>Untar the contents into the <code>sysroots/aarch64-xilinx-linux</code> directory of the petalinux system. Do not delete the tar file yet, as this file will still be needed when setting up the target board.</li>
</ol>
<pre class="hljs"><code><div>tar -xzvf vitis_ai_2020.2-r1.3.2.tar.gz -C [INSTALLATION-DIRECTORY]/sysroots/aarch64-xilinx-linux
</div></code></pre>
<h3 id="xilinx-unified-software-platform-installation"><strong>Xilinx Unified Software Platform Installation</strong></h3>
<ol>
<li>Download the Xilinx Unified Software Platform 2020.2 self-extracting web installer from the <a href="https://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/vitis/archive-vitis.html">Xilinx download archives</a>. Execute the binary file <strong>with administrative/sudo rights</strong> to launch the Xilinx GUI installation interface.</li>
</ol>
<pre class="hljs"><code><div>sudo ./Xilinx_Unified_2020.2_1118_1232_Lin64.bin
</div></code></pre>
<ol start="2">
<li>When the installation is complete, run <code>source</code> on the <code>environment-setup-aarch64-xilinx-linux</code> file.</li>
</ol>
<pre class="hljs"><code><div>source [INSTALLATION-DIRECTORY]/Vitis/2020.2/settings64.sh 
source [INSTALLATION-DIRECTORY]/Vitis_HLS/2020.2/settings64.sh 
source [INSTALLATION-DIRECTORY]/Vivado/2020.2/settings64.sh 
</div></code></pre>
<h3 id="avnet-ultrazed-eg-iocc-base-vitis-platform-project-download"><strong>Avnet UltraZed-EG IOCC Base Vitis Platform Project Download</strong></h3>
<ol>
<li>
<p>Navigate to the <code>/2020.2/Vitis_Platform/uz3eg_iocc_vitis_2020_2.tar.gz</code> path on the <a href="https://avnet.me/ZedSupport">Avnet sharepoint site</a> to download the base Vitis Platform Project.</p>
</li>
<li>
<p>Extract the tar file once it has been downloaded.</p>
</li>
</ol>
<pre class="hljs"><code><div>tar -zxvf uz3eg_iocc_vitis_2020_2.tar.gz
</div></code></pre>
<h3 id="dogs-vs-cats-data-download"><strong>Dogs vs Cats Data Download</strong></h3>
<p>The sample data used by this guide can be downloaded <a href="https://www.kaggle.com/competitions/dogs-vs-cats/data">here</a>. Unzip the zipped datasets.</p>
<h3 id="xilinx-vitis-ai-docker-image-download"><strong>Xilinx Vitis-AI Docker Image Download</strong></h3>
<p>Ensure that Docker has been installed on the computer. Start the Docker service and pull the Xilinx Docker image onto the local host.</p>
<pre class="hljs"><code><div># Enable and start Docker service.
sudo systemctl enable docker
sudo systemctl start docker

# Pull the Docker image.
docker pull xilinx/vitis-ai:1.3.598
</div></code></pre>
<p>Refer to the <a href="#docker-permission-denied">common issues</a> section if the pull command throws a &quot;permission denied&quot; error.</p>
<h3 id="xilinx-vitis-ai-git-repository-download"><strong>Xilinx Vitis-AI Git Repository Download</strong></h3>
<p>Clone branch 1.3.2 of the <a href="https://github.com/Xilinx/Vitis-AI/tree/1.3.2">Vitis-AI repository</a> onto the local host.</p>
<pre class="hljs"><code><div>git clone -b 1.3.2 --recurse-submodules https://github.com/Xilinx/Vitis-AI.git
</div></code></pre>
<h3 id="xilinx-vitis-ai-tutorials-git-repository-download"><strong>Xilinx Vitis-AI-Tutorials Git Repository Download</strong></h3>
<p>Clone branch 1.3.2 of the <a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/1.3">Vitis-AI repository</a> onto the local host.</p>
<pre class="hljs"><code><div>git clone -b 1.3.2 --recurse-submodules https://github.com/Xilinx/Vitis-AI-Tutorials.git
</div></code></pre>
<h3 id="xilinx-zynqmp-common-image-download"><strong>Xilinx ZYNQMP Common Image Download</strong></h3>
<p>Download the Xilinx ZYNQMP common image for Embedded Vitis Platforms from the <a href="#https://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/embedded-design-tools/archive.html">Xilinx common image archive</a>. Ensure that version <strong>2020.2</strong>  is selected.</p>
<p>Extract the tar file downloaded.</p>
<pre class="hljs"><code><div>tar -zxvf xilinx-zynqmp-common-v2020.2.tar.gz
</div></code></pre>
<h2 id="12-setting-up-the-workspace">1.2. Setting up the workspace</h2>
<ol>
<li>Create a workspace directory containing the following items:
<ul>
<li><a href="#Avnet-Ultrazed-EG-IOCC-base-Vitis-Platform-Project-download">Avnet UltraZed-EG IOCC base Vitis Platform Project (extracted)</a></li>
<li><a href="#Xilinx-Vitis-AI-git-repository-download">Xilinx Vitis-AI Git repository v1.3.2</a></li>
<li><a href="#Xilinx-Vitis-AI-tutorials-git-repository-download">Xilinx Vitis-AI-Tutorials Git repository v1.3</a></li>
<li><a href="#Xilinx-ZYNQMP-Common-Image">Xilinx ZYNQMP common image (extracted)</a></li>
</ul>
</li>
</ol>
<pre class="hljs"><code><div>  ├── uz3eg_iocc_base
  ├── Vitis-AI
  ├── Vitis-AI-Tutorials
  └── xilinx-zynqmp-common-v2020.2
</div></code></pre>
<ol start="2">
<li>Make a copy of the <code>dsa/DPU-TRD</code> directory from the Vitis-AI repository in the workspace directory. Rename it to <code>DPU-TRD-uz3eg_iocc</code>. This directory contains the DPU IP information, neccessary for setting up the DPU on the board's PL.
(Run the following commands from the workspace directory we just created.)</li>
</ol>
<pre class="hljs"><code><div>cp -r ./Vitis-AI/dsa/DPU-TRD .
mv DPU-TRD DPU-TRD-uz3eg_iocc
</div></code></pre>
<ol start="3">
<li>Make a copy of the <code>Design_Tutorials/08-tf2_flow</code> directory from the Vitis-AI-Tutorials repository in the Vitis-AI directory. This will be the sample model which we will be working on in this guide.
(Run the following commands from the workspace directory we just created.)</li>
</ol>
<pre class="hljs"><code><div>cp -r ./Vitis-AI-Tutorials/Design_Tutorials/08-tf2_flow ./Vitis-AI
</div></code></pre>
<ol start="4">
<li>Move the <a href="#dogs-vs-cats-data-download">Dogs vs Cats dataset</a> into the <code>08-tf2_flow/files</code> directory.</li>
</ol>
<p>Your workspace should look something like this now:</p>
<pre class="hljs"><code><div>├── DPU-TRD-uz3eg_iocc
├── uz3eg_iocc_base
├── Vitis-AI
│   ├── 08-tf2_flow          # 08-tf2_flow should be under the Vitis-AI directory
│   │   ├── files
│   │   │  ├── dogs-vs-cats  # Dataset from Kaggle should be under the 08-tf2_flow/files directory
│   │   │  ...
│   │   ...
│   ...
├── Vitis-AI-Tutorials
└── xilinx-zynqmp-common-v2020.2
</div></code></pre>
<h2 id="13-setting-up-the-environment-variables">1.3. Setting up the environment variables</h2>
<p>This section will be about the set up of the environment variables. This step is crucial in ensuring that the scripts and executables provided by the Vitis-AI repository work properly. Create the following environments:
* <code>VITIS_AI_HOME</code>: <strong>Absolute</strong> path of the Vitis-AI Git repository
* <code>SDX_PLATFORM</code>: <strong>Absolute</strong> path of the <code>.xpfm</code> file in the Avnet UltraZed-EG IOCC Base Vitis Platform Project
* <code>TRD_HOME</code>: <strong>Absolute</strong> path of the DPU-TRD-uz3eg_iocc directory created earlier
* <code>EDGE_COMMON_SW</code>:<strong>Absolute</strong> path of the Xilinx Zynqmp common image</p>
<p>Run the following command from the workspace directory <a href="#12-setting-up-the-workspace">created earlier</a>:</p>
<pre class="hljs"><code><div>export VITIS_AI_HOME=${PWD}/Vitis-AI
export SDX_PLATFORM=${PWD}/uz3eg_iocc_base/uz3eg_iocc_base.xpfm
export TRD_HOME=${PWD}/DPU-TRD-uz3eg_iocc
export EDGE_COMMON_SW=${PWD}/xilinx-zynqmp-common-image-v2020.2
</div></code></pre>
<p>We are now ready to begin configuring the DPU.</p>
<h1 id="2-configuring-the-dpu-ip">2. Configuring the DPU IP</h1>
<p>The DPU configuration to be used by the UltraZed-EG is the DPUCZDX8G. Navigate to the <code>DPU-TRD-uz3eg_iocc/prj/Vitis</code> directory:</p>
<pre class="hljs"><code><div>cd DPU-TRD-uz3eg_iocc/prj/Vitis
</div></code></pre>
<p>We will be editting the following files in this directory:</p>
<pre class="hljs"><code><div>Workspace/DPU-TRD-uz3eg_iocc
  ├── prj
  │   ├── Vitis
  │   │   ├── config_file
  │   │   │   ├── prj_config      # We will be making changes to this file
  │   │   │   ...
  │   │   ├── dpu_conf.vh         # and also this file
  │   │   ...
  │   ...
  ...
</div></code></pre>
<h2 id="21-changes-to-the-dpuconfvh-file">2.1. Changes to the <code>dpu_conf.vh</code> file:</h2>
<ol>
<li><strong>Line 26</strong>: We change the DPU convolution architecture to <code>B2304</code>. The number within the convolution architecture’s name (i.e., 2304) represents the peak operations per clock cycle. A larger number implies faster DPU performance, but also signifies a larger number of DSP slices being used in the board. For the UltraZed-EG, B2304 is the best architecture available for the UltraZed-EG, given the DSP slices available.</li>
</ol>
<pre class="hljs"><code><div>/*====== Architecture Options ======*/
// |------------------------------------------------------|
// | Support 8 DPU size
// | It relates to model. if change, must update model
// +------------------------------------------------------+
// | `define B512               
// +------------------------------------------------------+
// | `define B800                 
// +------------------------------------------------------+
// | `define B1024                 
// +------------------------------------------------------+
// | `define B1152                 
// +------------------------------------------------------+
// | `define B1600                 
// +------------------------------------------------------+
// | `define B2304                 
// +------------------------------------------------------+
// | `define B3136                 
// +------------------------------------------------------+
// | `define B4096                 
// |------------------------------------------------------|

`define B2304 
</div></code></pre>
<ol start="2">
<li><strong>Line 41 – 43</strong>: In this step, we update the URAM configurations to suit our UltraZed-EG. Although URAM will not be used in this specific project, this step will come in handy should we decide to utilize the URAM in future projects.</li>
</ol>
<pre class="hljs"><code><div>// |------------------------------------------------------|
// | If the FPGA has Uram. You can define URAM_EN parameter  
// | if change, Don't need update model
// +------------------------------------------------------+
// | for zcu104 : `define URAM_ENABLE               
// +------------------------------------------------------+
// | for zcu102 : `define URAM_DISABLE                 
// |------------------------------------------------------|

`define URAM_DISABLE 

//config URAM
`ifdef URAM_ENABLE
    `define def_UBANK_IMG_N          4
    `define def_UBANK_WGT_N          13
    `define def_UBANK_BIAS           1
`elsif URAM_DISABLE
    `define def_UBANK_IMG_N          0
    `define def_UBANK_WGT_N          0
    `define def_UBANK_BIAS           0
`endif
</div></code></pre>
<ol start="3">
<li><strong>Line 148</strong>: In this step, we change the DSP usage to low, to ensure the DSP slices used is within the specifications afforded by the board.</li>
</ol>
<pre class="hljs"><code><div>// |------------------------------------------------------|
// | DSP48 Usage Configuration  
// | Use dsp replace of lut in conv operate 
// | if change, Don't need update model
// +------------------------------------------------------+
// | `define DSP48_USAGE_HIGH              
// +------------------------------------------------------+
// | `define DSP48_USAGE_LOW                
// |------------------------------------------------------|

`define DSP48_USAGE_LOW 
</div></code></pre>
<p>Here's a script to make the above changes automatically:</p>
<pre class="hljs"><code><div># Choose DPU architecture for our project
sed -i '26s/.*/`define B2304 /' dpu_conf.vh

# Update URAM configurations for UltraZed-EG
sed -i '41s/.*/    `define def_UBANK_IMG_N          4/' dpu_conf.vh
sed -i '42s/.*/    `define def_UBANK_WGT_N          13/' dpu_conf.vh

# Update DSP usage configuration for UltraZed-EG
sed -i '148s/.*/`define DSP48_USAGE_LOW /' dpu_conf.vh

</div></code></pre>
<h2 id="22-changes-to-the-configfileprjconfig-file">2.2. Changes to the <code>config_file/prj_config</code> file:</h2>
<p>Next, we modify the <code>config_file/prj_config</code>. This file allows one to set the clock speed and the number of DPU cores. The UltraZed-EG only have sufficient resources for a single DPU core. Hence, the configurations under <code>[clock]</code> and <code>[connectivity]</code> are as follows:</p>
<ol>
<li>We first change the <code>[clock]</code> section to modify the clock speeds. We will use <code>150000000</code>Hz for <code>1.aclk</code> and <code>300000000</code>Hz for <code>1.ap_clk_2</code>.
<code>2.aclk</code> and <code>2.ap_clk_2</code> is commented out since DPUCZDX8G only has a single core. Note that <code>ap_clk_2</code> <strong>must be twice the frequency</strong> of <code>aclk</code>.</li>
</ol>
<pre class="hljs"><code><div>[clock]

freqHz=150000000:DPUCZDX8G_1.aclk
freqHz=300000000:DPUCZDX8G_1.ap_clk_2
# freqHz=300000000:DPUCZDX8G_2.aclk
# freqHz=600000000:DPUCZDX8G_2.ap_clk_2
</div></code></pre>
<ol start="2">
<li>We then change the <code>[connectivity]</code> section for selecting the AXI connections. Since DPUCZDX8G only has a single core, the connections of <code>DPUCZDX8G_2</code> are commented out. Finally, we change the core count to 1.</li>
</ol>
<pre class="hljs"><code><div>[connectivity]

sp=DPUCZDX8G_1.M_AXI_GP0:HPC0
sp=DPUCZDX8G_1.M_AXI_HP0:HP0
sp=DPUCZDX8G_1.M_AXI_HP2:HP1
# sp=DPUCZDX8G_2.M_AXI_GP0:HPC0
# sp=DPUCZDX8G_2.M_AXI_HP0:HP2
# sp=DPUCZDX8G_2.M_AXI_HP2:HP3

nk=DPUCZDX8G:1
</div></code></pre>
<p>Here's a script to make the above changes automatically:</p>
<pre class="hljs"><code><div># Set clock frequency for DPU
sed -i '20s/.*/freqHz=150000000:DPUCZDX8G_1.aclk/' config_file/prj_config
sed -i '21s/.*/freqHz=300000000:DPUCZDX8G_1.ap_clk_2/' config_file/prj_config
sed -i '22s/.*/# freqHz=300000000:DPUCZDX8G_2.aclk/' config_file/prj_config
sed -i '23s/.*/# freqHz=600000000:DPUCZDX8G_2.ap_clk_2/' config_file/prj_config

# Set AXI connections for DPU
sed -i '30s/.*/# sp=DPUCZDX8G_2.M_AXI_GP0:HPC0/' config_file/prj_config
sed -i '31s/.*/# sp=DPUCZDX8G_2.M_AXI_HP0:HP2/' config_file/prj_config
sed -i '32s/.*/# sp=DPUCZDX8G_2.M_AXI_HP2:HP3/' config_file/prj_config

# Update DPU core count
sed -i '35s/.*/nk=DPUCZDX8G:1/' config_file/prj_config

</div></code></pre>
<h1 id="3-creating-the-bootable-sd-card-image">3. Creating The Bootable SD Card Image</h1>
<p>While still within the <code>DPU-TRD-uz3eg_iocc/prj/Vitis</code> directory, run the following command to build the bootable SD image:</p>
<pre class="hljs"><code><div>make KERNEL=DPU DEVICE=uz3eg_iocc 
</div></code></pre>
<p>This should generate the necessary files for our SD card within the<br>
DPU-TRD-uz3eg_iocc/prj/Vitis/binary_container_1 directory:</p>
<pre class="hljs"><code><div>.
├── BOOT.BIN
├── dpu.xclbin                       # This file will be needed when running apps on target
├── dpu.xclbin.info
├── dpu.xclbin.link_summary
├── dpu.xo
├── ip_cache
├── link
├── logs
├── reports
├── sd_card
│   ├── arch.json                    # This file will be needed for cross-compilation
│   ├── BOOT.BIN
│   ├── boot.scr
│   ├── dpu.xclbin                  
│   ├── Image
│   ├── image.ub
│   ├── init.sh
│   ├── platform_desc.txt
│   ├── rootfs.tar.gz
│   └── uz3eg_iocc_base.hwh
├── uz3eg_iocc_base.bif
├── uz3eg_iocc_base.img             # SD card image can be found here
├── v++_link_dpu_guidance.json
└── v++_link_dpu_guidance.pb

</div></code></pre>
<p>If you encounter the <code>/bin/Vivado: Command not found</code>, it is likely that the <code>settings64.sh</code> files within the Xilinx Unfied Software Platform installation directories have yet to be <code>source</code>-ed. Refer to <a href="#binvivado--command-not-found-error-when-building-sd-card-image">here</a>.</p>
<h1 id="4-running-the-tensorflow2-application-on-target">4. Running the TensorFlow2 application on target</h1>
<p>To quantize and compile TensorFlow2 models in Vitis-AI, the pre-trained model should be a <code>.h5</code> file. For this guide, we will be using the pretrained model <code>f_model.h5</code> provided under the <code>08-tf2_flow/files/pretrained</code>.</p>
<h2 id="41-quantizing-the-model">4.1. Quantizing The Model</h2>
<p>We will be using the <a href="https://github.com/teoyuqi/Running-Vitis-AI-on-Avnet-UltraZed-EG-IOCC/blob/main/my_quantize.py">simplified quantizer file</a> named <code>my_quantizer.py</code>. This file should be placed wthin the <code>08-tf2_flow/files</code> directory:</p>
<pre class="hljs"><code><div>Vitis-AI
├── 08-tf2_flow
│   ├── files
│   │   ├── my_quantize.py
│   │   ...
│   ...
...
</div></code></pre>
<p>The main lines involving the Vitis-AI quantizer are lines 1, 25 and 26:</p>
<ul>
<li><strong>Line 1</strong>: Import <code>vitis_quantize</code>.</li>
</ul>
<pre class="hljs"><code><div>|01| from tensorflow_model_optimization.quantization.keras import vitis_quantize
</div></code></pre>
<ul>
<li><strong>Line 25</strong>: The <code>vitis_quantize.VitisQuantizer</code> constructor takes in a pre-trained <code>.h5</code> model and returns a <code>VitisQuantizer</code> object for the model.</li>
</ul>
<pre class="hljs"><code><div>|25| quantizer = vitis_quantize.VitisQuantizer(PRETRAINED_MODEL_PATH)
</div></code></pre>
<ul>
<li><strong>Line 26</strong>: Use the <code>VitisQuantizer</code> object's <code>quantize_model()</code> method to pass in the calibration dataset as a <code>tf.data.Dataset</code> object and quantize the model.</li>
</ul>
<pre class="hljs"><code><div>|26| quantized_model = quantizer.quantize_model(calib_dataset=quant_dataset)
</div></code></pre>
<p>Enter the Vitis-AI repository and use the <code>docker_run.sh</code> script to start the Vitis-AI Docker image downloaded previously.</p>
<pre class="hljs"><code><div>cd ${VITIS_AI_HOME}
./docker_run.sh xilinx/vitis-ai:1.3.598
</div></code></pre>
<p>Activate the Tensorflow2 python virtual environment with <code>conda activate vitis-ai-tensorflow2</code></p>
<pre class="hljs"><code><div>conda activate vitis-ai-tensorflow2
</div></code></pre>
<p>Enter the <code>08-tf2_flow/files</code> directory:</p>
<pre class="hljs"><code><div>cd 08-tf2_flow/files
</div></code></pre>
<p>Run <code>my_quantize.py</code>.</p>
<pre class="hljs"><code><div>python my_quantize.py
</div></code></pre>
<p>This generates the quantized model as <code>q_model.h5</code></p>
<p>Exit the Docker environment:</p>
<pre class="hljs"><code><div>conda deactivate
exit
</div></code></pre>
<h2 id="42-cross-compiling-the-model">4.2. Cross-compiling the Model</h2>
<ol>
<li>Copy the arch.json file from the binary container sd_card directory to the <code>08-tf2_flow/files</code> directory. This file specifies the DPU architecture which the application should be compiled for.</li>
</ol>
<pre class="hljs"><code><div>cp ../../../DPU-TRD-uz3eg_iocc/prj/Vitis/binary_container_1/sd_card/arch.json .
</div></code></pre>
<pre class="hljs"><code><div>Vitis-AI
├── 08-tf2_flow
│   ├── files
│   │   ├── arch.json     &lt;-- arch.json should end up here, alongside the .h5 file.
│   │   ├── q_model.h5
│   │   ...
│   ...
...
</div></code></pre>
<ol start="2">
<li>Once again, return to the Vitis-AI repository and use the <code>docker_run.sh</code> script to start the Vitis-AI Docker image downloaded previously.</li>
</ol>
<pre class="hljs"><code><div>cd ${VITIS_AI_HOME}
./docker_run.sh xilinx/vitis-ai:1.3.598
</div></code></pre>
<ol start="3">
<li>Activate the Tensorflow2 python virtual environment with <code>conda activate vitis-ai-tensorflow2</code></li>
</ol>
<pre class="hljs"><code><div>conda activate vitis-ai-tensorflow2
</div></code></pre>
<ol start="4">
<li>Compile the quantized model using the <code>vai_c_tensorflow2</code> command in the Docker image. Note the following flags and their usages
<ul>
<li>--model : Specify the path to the quantized <code>.h5</code> model after this flag.</li>
<li>--arch : Specify the path to the <code>arch.json</code> file after this flag. This file can be foudn in the binary container generated <a href="#3-creating-the-bootable-sd-card-image">earlier</a>.</li>
<li>--output_dir : Specify the output path of the compiled <code>.xmodel</code> file after this flag.</li>
<li>--net_name : Specify the compiled model's name after this flag</li>
</ul>
</li>
</ol>
<pre class="hljs"><code><div># Return to directory with quantized model
cd 08-tf2_flow/files

# Use vai_c_tensorflow2
vai_c_tensorflow2 \
    --model ./q_model.h5 \
    --arch ./arch.json \
    --output_dir ./ \
    --net_name dog-v-cat-cnn
</div></code></pre>
<p>This generates a <code>dogs-v-cats-cnn.xmodel</code> binary for the target board.</p>
<ol start="5">
<li>For the purpose of this guide, we will generate a small dataset for the model as well.</li>
</ol>
<pre class="hljs"><code><div>python target.py --image_dir test --target_dir target2 --num_images 1000
</div></code></pre>
<ol start="6">
<li>Exit the Docker environment:</li>
</ol>
<pre class="hljs"><code><div>conda deactivate
exit
</div></code></pre>
<h2 id="43-vitis-ai-runtime-vart-and-vitis-ai-modelzoo">4.3. Vitis AI Runtime (VART) and Vitis AI Modelzoo</h2>
<p>Xilinx provides a set of VART APIs for programming applications to call the cross-compiled models on the target. These APIs are available in both <a href="https://docs.xilinx.com/r/1.3-English/ug1414-vitis-ai/C-APIs?tocId=kK2cPy6Jd24R7X6JQp3RZA">C++</a> and <a href="https://docs.xilinx.com/r/1.3-English/ug1414-vitis-ai/Python-APIs?tocId=qtPOpMbsGMviWjwD~QnDfg">Python</a>.</p>
<p>For this guide, we will be using the VART application provided in the Vitis-AI tutorial for tensorflow:</p>
<pre class="hljs"><code><div>Vitis-AI
├── 08-tf2_flow
│   ├── files
│   │   ├── application
│   │   │   └──  app_mt.py      # This is the VART application that will be used to call the xmodel
│   │   ...
│   ...
...
</div></code></pre>
<p>Vitis AI also has a series of prebuilt AI models known as the <a href="https://github.com/Xilinx/Vitis-AI/tree/1.3.2/models/AI-Model-Zoo/model-list">modelzoo</a>. Each of the <code>.yaml</code> files in the repository contains the download links for the model.</p>
<ul>
<li>These models are <strong>quantized but not compiled</strong>. <code>vai_c</code> is needed to cross-compile the models.</li>
<li>This <a href="https://github.com/Avnet/vitis/blob/2020.2/app/zoo/compile_modelzoo.sh">link</a> provides a script to automatically download and cross-compile all models in the modelzoo. However, do note that the <code>arch.json</code> file should be present in the same directory.</li>
<li>Most models in the modelzoo have their <a href="https://github.com/Xilinx/Vitis-AI/tree/1.3.2/demo/VART">corresponding VART application</a> prepared by Xilinx for calling the model on the target board. These VART applications are available in either C++ or Python. Note that C++ VART applications will have to be compiled using the <code>build.sh</code> scripts present.</li>
<li>There is also a <a href="https://github.com/Xilinx/Vitis-AI/tree/1.3.2/demo/Vitis-AI-Library/samples">Vitis-AI library</a> which is a set of tools prepared by Xilinx for testing the modelzoo models. They are also built on the VART API.</li>
</ul>
<h1 id="5-setting-up-the-sd-card">5. Setting Up The SD Card</h1>
<ol>
<li>Insert and mount the SD card. Next, use the Linux <code>dd</code> tool to burn the <code>.img</code> file in the binary container onto the SD card.</li>
</ol>
<pre class="hljs"><code><div># Replace sd{X} with the partition which the SD card was mounted in.
sudo dd bs=4M if=${DPU_TRD_HOME}/prj/Vitis/binary_container1/uz3eg_iocc_base.img of=/dev/sd{X} status=progress conv=fsync
</div></code></pre>
<ol start="2">
<li>
<p>Extract the <a href="https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_2020.2-r1.3.2.tar.gz">vitis_ai_2020.2-r1.3.2.tar.gz</a> file downloaded during the <a href="#vitis-ai-runtime-vart-set-up">VART set up</a> earlier. Copy the <code>etc/*</code> and <code>usr/*</code> files over to <code>/usr</code> and <code>/etc</code> directories of the SD card's RootFS partition respectively.</p>
</li>
<li>
<p>Copy the <code>dpu.xclbin</code> file from <code>${DPU_TRD_HOME}/prj/Vitis/binary_container1/dpu.xclbin</code> to the <code>/media/Sd-mmcblk0p1</code> directory of the SD card's RootFS partition.</p>
</li>
<li>
<p>Remove the <code>xir</code> directory and the <code>runner.so</code> file under the <code>/usr/lib/python3.7/site-packages</code> directory.</p>
</li>
<li>
<p>Copy the following files over to the SD card as well:</p>
<ul>
<li>Cross-compiled <code>dogs-v-cats-cnn.xmodel</code> from <code>${VITIS_AI_HOME}/08-tf2_flow/files</code></li>
<li>VART application <code>app_mt.py</code> from <code>${VITIS_AI_HOME}/08-tf2_flow/files/application/app_mt.py</code></li>
<li><code>test</code> directory with the test data from <code>${VITIS_AI_HOME}/08-tf2_flow/files/test</code></li>
<li><code>dpu_sw_optimize.tar.gz</code> file from <code>${TRD_HOME}/app/dpu_sw_optimize.tar.gz</code></li>
</ul>
</li>
</ol>
<h1 id="6-booting-up-the-board">6. Booting Up The Board</h1>
<ol>
<li>
<p>Insert the SD card prepared <a href="#5-setting-up-the-sd-card">earlier</a> in the board and power it up.</p>
</li>
<li>
<p>Use the Screen tool to set up a serial connection from the host to the target board.</p>
</li>
</ol>
<pre class="hljs"><code><div>sudo Screen /dev/ttyUSB1 115200
</div></code></pre>
<ol start="3">
<li>Extract the <code>dpu_sw_optimize.tar.gz</code> and execute the <code>dpu_sw_optimize/zynqmp/zynqmp_dpu_optimize.sh</code> script</li>
</ol>
<pre class="hljs"><code><div>tar -zxvf dpu_sw_optimize.tar.gz
cd dpu_sw_optimize/zynqmp
bash zynqmp_dpu_optimize.sh
cd ../..
</div></code></pre>
<ol start="4">
<li>The models can now be executed using a command of the following format:
<ul>
<li>C++ VART applications: <code>[VART APPLICATION] [XMODEL] [DATA]</code></li>
<li>Python VART applications: <code>python [VART APPLICATION] [XMODEL] [DATA]</code></li>
</ul>
</li>
</ol>
<p>For out case, this would be:</p>
<pre class="hljs"><code><div>python app_mt.py dogs-v-cats-cnn.xmodel test
</div></code></pre>
<h1 id="common-issues">Common Issues</h1>
<h2 id="docker-permission-denied">Docker Permission Denied</h2>
<p><em>This section is adapted from this <a href="https://stackoverflow.com/questions/48957195/how-to-fix-docker-got-permission-denied-issue">StackOverflow tread</a>.</em>
<br/>
A common error encountered when running Docker commands is the <code>permissions denied</code> error:</p>
<pre class="hljs"><code><div>$~: docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: 
... ... ... dial unix /var/run/docker.sock: connect: permission denied. See 'docker run --help'
</div></code></pre>
<ol>
<li>Create a new users group and add the user into it.</li>
</ol>
<pre class="hljs"><code><div># Create a &quot;docker&quot; user group if it does not exist.
sudo groupadd docker
# Add your user to the docker group.
sudo usermod -aG docker $USER
# Switch session to the newly created group.
newgrp docker
# Restart Docker
sudo systemctl restart docker.
</div></code></pre>
<ol start="2">
<li>If the problem persists, try adding read and write rights to the Docker daemon.</li>
</ol>
<pre class="hljs"><code><div>sudo chmod 666 /var/run/docker.sock
</div></code></pre>
<h2 id="binvivado--command-not-found-error-when-building-sd-card-image"><code>/bin/Vivado : Command not found</code> error when building SD card image</h2>
<p>It is likely that the settings64.sh files in the installation directory of the Xilinx Unified Software Platform application have yet to be executed. These files have to be executed each time a new terminal is opened, in order to set up the environment.</p>
<pre class="hljs"><code><div>source [XILINX UNIFIED SOFTWARE PLATFORM INSTALLATION DIRECTORY]/Vitis/2020.2/settings64.sh
source [XILINX UNIFIED SOFTWARE PLATFORM INSTALLATION DIRECTORY]/Vitis_HLS/2020.2/settings64.sh
source [XILINX UNIFIED SOFTWARE PLATFORM INSTALLATION DIRECTORY]/Vivado/2020.2/settings64.sh
</div></code></pre>
<h2 id="attributeerror-module-xir-has-no-attribute-graph-error-when-running-application-on-target"><code>AttributeError: module 'xir' has no attribute 'Graph'</code> error when running application on target</h2>
<p>Remove the <code>xir</code> directory and the <code>runner.so</code> file under the <code>/usr/lib/python3.7/site-packages</code> directory of the SD card. See <a href="https://github.com/Xilinx/Vitis-AI/issues/280#issuecomment-768794051">Github comment</a>.</p>

</body>
</html>
